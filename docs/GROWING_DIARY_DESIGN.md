# è‚²æˆæ—¥è¨˜è‡ªå‹•ç”Ÿæˆæ©Ÿèƒ½ã®è¨­è¨ˆ (Growing Diary Auto-Generation Design)

## ğŸ“‹ è¦ä»¶å®šç¾© (Requirements)

### æ©Ÿèƒ½æ¦‚è¦
ã‚¨ãƒƒã‚¸ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ã‚°ã‚’æ¯æ—¥è§£æã—ã€AIã‚’æ´»ç”¨ã—ã¦è‚²æˆæ—¥è¨˜ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹æ©Ÿèƒ½ã€‚

### ä¸»è¦è¦ä»¶
1. **æ¯æ—¥ã®è‡ªå‹•å®Ÿè¡Œ**: æŒ‡å®šæ™‚åˆ»ã«è‡ªå‹•ã§æ—¥è¨˜ã‚’ç”Ÿæˆ
2. **ãƒ­ã‚°è§£æ**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ­ã‚°ã¨ã‚»ãƒ³ã‚µãƒ¼ãƒ­ã‚°ã‚’çµ±åˆåˆ†æ
3. **AIç”Ÿæˆ**: Gemini APIã‚’æ´»ç”¨ã—ã¦è‡ªç„¶ãªæ—¥è¨˜æ–‡ã‚’ç”Ÿæˆ
4. **ãƒ‡ãƒ¼ã‚¿ä¿å­˜**: Firestoreã«æ—¥è¨˜ã‚’ä¿å­˜
5. **UIè¡¨ç¤º**: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§æ—¥è¨˜ã‚’é–²è¦§å¯èƒ½

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼ â†’ ã‚·ã‚¹ãƒ†ãƒ è‡ªå‹•å®Ÿè¡Œï¼ˆæ¯æ—¥23:50ï¼‰
           â†“
        1. å½“æ—¥ã®ãƒ­ã‚°åé›†
           - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œãƒ­ã‚°
           - ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å±¥æ­´
           - æ¤ç‰©ç”»åƒï¼ˆã‚«ãƒ¡ãƒ©ãƒ‡ãƒ¼ã‚¿ï¼‰
           â†“
        2. AIåˆ†æãƒ»æ—¥è¨˜ç”Ÿæˆ
           - ãƒ­ã‚°ã®è¦ç´„
           - ç•°å¸¸æ¤œçŸ¥
           - æˆé•·è¦³å¯Ÿ
           - æ”¹å–„ææ¡ˆ
           â†“
        3. ä¿å­˜
           - Firestore: growing_diaries ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
           â†“
        4. é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
           - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ç”Ÿæˆå®Œäº†é€šçŸ¥
```

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ (System Design)

### 1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```mermaid
graph TB
    subgraph "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"
        CRON[Cloud Scheduler]
    end
    
    subgraph "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰"
        API[FastAPI Endpoint]
        DIARY[Diary Service]
        COLLECT[Data Collector]
        AI[AI Generator]
    end
    
    subgraph "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹"
        AGENT_LOG[(agent_execution_logs)]
        SENSOR_LOG[(sensor_logs)]
        PLANT_IMG[(plant_camera)]
        VEG[(vegetables)]
    end
    
    subgraph "AI ã‚µãƒ¼ãƒ“ã‚¹"
        GEMINI[Gemini API]
    end
    
    subgraph "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"
        DIARY_DB[(growing_diaries)]
    end
    
    subgraph "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"
        DIARY_UI[Diary View Page]
    end
    
    CRON -->|HTTP POST| API
    API --> DIARY
    DIARY --> COLLECT
    COLLECT --> AGENT_LOG
    COLLECT --> SENSOR_LOG
    COLLECT --> PLANT_IMG
    COLLECT --> VEG
    DIARY --> AI
    AI --> GEMINI
    DIARY --> DIARY_DB
    DIARY_UI --> DIARY_DB
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ

#### æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: `growing_diaries`

```typescript
interface GrowingDiary {
  id: string                    // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDï¼ˆä¾‹: "2025-02-04"ï¼‰
  date: string                  // æ—¥ä»˜ï¼ˆISO 8601å½¢å¼ï¼‰
  created_at: Timestamp         // ä½œæˆæ—¥æ™‚
  vegetable_id?: string         // å¯¾è±¡é‡èœã®IDï¼ˆç¾åœ¨è‚²æˆä¸­ã®é‡èœï¼‰
  vegetable_name?: string       // é‡èœå
  
  // çµ±è¨ˆæƒ…å ±
  statistics: {
    temperature: {
      min: number
      max: number
      avg: number
    }
    humidity: {
      min: number
      max: number
      avg: number
    }
    soil_moisture: {
      min: number
      max: number
      avg: number
    }
    agent_actions_count: number  // ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œå›æ•°
  }
  
  // ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆ
  events: Array<{
    time: string                // æ™‚åˆ»
    type: string                // 'action' | 'warning' | 'alert' | 'info'
    device?: string             // ãƒ‡ãƒã‚¤ã‚¹å
    action: string              // ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹
    comment?: string            // ã‚³ãƒ¡ãƒ³ãƒˆ
  }>
  
  // AIç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„
  ai_summary: string            // AIã«ã‚ˆã‚‹1æ—¥ã®è¦ç´„ï¼ˆ200-300æ–‡å­—ï¼‰
  observations: string          // æˆé•·è¦³å¯Ÿï¼ˆ100-200æ–‡å­—ï¼‰
  recommendations: string       // æ˜æ—¥ã¸ã®æ”¹å–„ææ¡ˆï¼ˆ100-150æ–‡å­—ï¼‰
  
  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ç”»åƒ
  plant_image_url?: string      // æ¤ç‰©ç”»åƒã®URL
  
  // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
  generation_status: 'pending' | 'processing' | 'completed' | 'failed'
  generation_time_ms?: number   // ç”Ÿæˆã«ã‹ã‹ã£ãŸæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
  error_message?: string        // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå¤±æ•—æ™‚ï¼‰
}
```

### 3. å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆ3ã¤ã®é¸æŠè‚¢ï¼‰

#### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ A: Cloud Scheduler + HTTP Endpointï¼ˆæ¨å¥¨ï¼‰

**æ¦‚è¦**: Google Cloud Schedulerã‹ã‚‰æ¯æ—¥HTTP POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… Google Cloudãƒã‚¤ãƒ†ã‚£ãƒ–
- âœ… è¨­å®šãŒç°¡å˜
- âœ… ã‚¹ã‚±ãƒ¼ãƒ«è‡ªå‹•ç®¡ç†
- âœ… Cloud Runã¨ã®ç›¸æ€§ãŒè‰¯ã„
- âœ… ãƒ­ã‚°ãƒ»ç›£è¦–ãŒå®¹æ˜“

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- âš ï¸ Cloud Schedulerè¨­å®šãŒå¿…è¦
- âš ï¸ èªè¨¼è¨­å®šãŒå¿…è¦

**å®Ÿè£…æ–¹æ³•**:
```bash
# Cloud Schedulerè¨­å®šã‚³ãƒãƒ³ãƒ‰
gcloud scheduler jobs create http daily-diary-generator \
  --schedule="50 23 * * *" \
  --uri="https://ai-batake-app-xxxxx.run.app/api/diary/generate-daily" \
  --http-method=POST \
  --oidc-service-account-email=scheduler@PROJECT_ID.iam.gserviceaccount.com \
  --location=us-central1 \
  --time-zone="Asia/Tokyo"
```

```python
# backend/diary_service.py
@app.post("/api/diary/generate-daily")
async def generate_daily_diary(background_tasks: BackgroundTasks):
    """
    Daily diary generation endpoint.
    Triggered by Cloud Scheduler.
    """
    # Verify request is from Cloud Scheduler
    # (Check OIDC token or IP whitelist)
    
    # Get yesterday's date (since runs at 23:50)
    target_date = (datetime.now() - timedelta(hours=1)).date()
    
    # Queue background task
    background_tasks.add_task(
        process_daily_diary, 
        target_date.isoformat()
    )
    
    return {
        "status": "accepted",
        "date": target_date.isoformat(),
        "message": "Diary generation started"
    }
```

#### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ B: Cloud Functions + Pub/Subï¼ˆä»£æ›¿æ¡ˆï¼‰

**æ¦‚è¦**: Cloud SchedulerãŒãƒˆãƒ”ãƒƒã‚¯ã«ç™ºè¡Œã€Cloud FunctionsãŒã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… ç–çµåˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- âœ… ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½å†…è”µ
- âœ… ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- âš ï¸ åˆ¥ã‚µãƒ¼ãƒ“ã‚¹ã®ç®¡ç†ãŒå¿…è¦
- âš ï¸ ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆé…å»¶
- âš ï¸ ãƒ‡ãƒ—ãƒ­ã‚¤ãŒè¤‡é›‘åŒ–

**å®Ÿè£…æ–¹æ³•**:
```python
# functions/diary_generator/main.py
import base64
import json
from google.cloud import firestore

def generate_diary(event, context):
    """Cloud Functions entry point"""
    # Decode Pub/Sub message
    if 'data' in event:
        data = json.loads(base64.b64decode(event['data']).decode())
    
    target_date = data.get('date', datetime.now().date().isoformat())
    
    # Call diary generation logic
    result = create_diary_for_date(target_date)
    
    print(f"Diary generated for {target_date}: {result}")
```

#### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ C: FastAPIå†…è”µã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ï¼ˆéæ¨å¥¨ï¼‰

**æ¦‚è¦**: APSchedulerãªã©ã‚’FastAPIå†…ã§å®Ÿè¡Œ

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… è¿½åŠ ã‚µãƒ¼ãƒ“ã‚¹ä¸è¦
- âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãŒç°¡å˜

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- âŒ Cloud Runã®è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã§åœæ­¢
- âŒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è¤‡æ•°æ™‚ã«é‡è¤‡å®Ÿè¡Œã®ãƒªã‚¹ã‚¯
- âŒ ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«å‹•ä½œã¯Cloud Runã«ä¸é©

**éæ¨å¥¨ç†ç”±**: Cloud Runã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã¹ã

### 4. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ­ã‚¸ãƒƒã‚¯

```python
# backend/diary_service.py
from datetime import datetime, timedelta, date
from typing import Dict, List, Any
import logging
from .db import db, get_agent_execution_logs, get_sensor_history

async def collect_daily_data(target_date: date) -> Dict[str, Any]:
    """
    æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    """
    # æ—¥ä»˜ç¯„å›²ã®è¨­å®šï¼ˆ0:00 - 23:59ï¼‰
    start_time = datetime.combine(target_date, datetime.min.time())
    end_time = datetime.combine(target_date, datetime.max.time())
    
    # 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œãƒ­ã‚°ã‚’å–å¾—
    agent_logs = await get_agent_logs_for_date(start_time, end_time)
    
    # 2. ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    sensor_data = await get_sensor_data_for_date(start_time, end_time)
    
    # 3. ç¾åœ¨ã®è‚²æˆé‡èœæƒ…å ±ã‚’å–å¾—
    current_vegetable = await get_current_vegetable()
    
    # 4. æ¤ç‰©ç”»åƒã‚’å–å¾—ï¼ˆæœ€æ–°ï¼‰
    plant_image = await get_plant_image_for_date(target_date)
    
    return {
        "date": target_date.isoformat(),
        "agent_logs": agent_logs,
        "sensor_data": sensor_data,
        "vegetable": current_vegetable,
        "plant_image": plant_image
    }

async def get_agent_logs_for_date(start: datetime, end: datetime) -> List[Dict]:
    """æŒ‡å®šæœŸé–“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ­ã‚°å–å¾—"""
    if db is None:
        return []
    
    try:
        docs = db.collection("agent_execution_logs") \
            .where("timestamp", ">=", start.isoformat()) \
            .where("timestamp", "<=", end.isoformat()) \
            .order_by("timestamp") \
            .stream()
        
        logs = []
        for doc in docs:
            log_data = doc.to_dict()
            log_data['id'] = doc.id
            logs.append(log_data)
        
        return logs
    except Exception as e:
        logging.error(f"Error fetching agent logs: {e}")
        return []

async def get_sensor_data_for_date(start: datetime, end: datetime) -> List[Dict]:
    """æŒ‡å®šæœŸé–“ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    if db is None:
        return []
    
    try:
        # Unix timestamp for query
        start_unix = int(start.timestamp())
        end_unix = int(end.timestamp())
        
        docs = db.collection("sensor_logs") \
            .where("unix_timestamp", ">=", start_unix) \
            .where("unix_timestamp", "<=", end_unix) \
            .order_by("unix_timestamp") \
            .stream()
        
        data = []
        for doc in docs:
            sensor_log = doc.to_dict()
            sensor_log['id'] = doc.id
            data.append(sensor_log)
        
        return data
    except Exception as e:
        logging.error(f"Error fetching sensor data: {e}")
        return []
```

### 5. çµ±è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯

```python
def calculate_statistics(sensor_data: List[Dict]) -> Dict:
    """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆã‚’è¨ˆç®—"""
    if not sensor_data:
        return {
            "temperature": {"min": 0, "max": 0, "avg": 0},
            "humidity": {"min": 0, "max": 0, "avg": 0},
            "soil_moisture": {"min": 0, "max": 0, "avg": 0},
        }
    
    temps = [d.get("temperature", 0) for d in sensor_data if d.get("temperature")]
    humids = [d.get("humidity", 0) for d in sensor_data if d.get("humidity")]
    soils = [d.get("soil_moisture", 0) for d in sensor_data if d.get("soil_moisture")]
    
    return {
        "temperature": {
            "min": round(min(temps), 1) if temps else 0,
            "max": round(max(temps), 1) if temps else 0,
            "avg": round(sum(temps) / len(temps), 1) if temps else 0,
        },
        "humidity": {
            "min": round(min(humids), 1) if humids else 0,
            "max": round(max(humids), 1) if humids else 0,
            "avg": round(sum(humids) / len(humids), 1) if humids else 0,
        },
        "soil_moisture": {
            "min": round(min(soils), 1) if soils else 0,
            "max": round(max(soils), 1) if soils else 0,
            "avg": round(sum(soils) / len(soils), 1) if soils else 0,
        },
    }

def extract_key_events(agent_logs: List[Dict], max_events: int = 10) -> List[Dict]:
    """é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’æŠ½å‡º"""
    events = []
    
    for log in agent_logs:
        log_data = log.get("data", {})
        timestamp = log.get("timestamp", "")
        
        # æ“ä½œã‚¤ãƒ™ãƒ³ãƒˆ
        if "operation" in log_data:
            for device, op in log_data["operation"].items():
                action = op.get("action", "")
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªæ“ä½œã®ã¿
                if "ON" in action or "OFF" in action or "èµ·å‹•" in action or "åœæ­¢" in action:
                    events.append({
                        "time": timestamp,
                        "type": "action",
                        "device": device,
                        "action": action
                    })
        
        # è­¦å‘Šãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ
        comment = log_data.get("comment", "")
        if "ç•°å¸¸" in comment or "ã‚¨ãƒ©ãƒ¼" in comment:
            events.append({
                "time": timestamp,
                "type": "alert",
                "action": comment
            })
        elif "è­¦å‘Š" in comment or "æ³¨æ„" in comment:
            events.append({
                "time": timestamp,
                "type": "warning",
                "action": comment
            })
    
    # æœ€å¤§ä»¶æ•°ã¾ã§
    return events[:max_events]
```

### 6. AIæ—¥è¨˜ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯

```python
# backend/diary_service.py
import os
import requests
import json

async def generate_diary_with_ai(
    date: str,
    statistics: Dict,
    events: List[Dict],
    vegetable_info: Dict
) -> Dict[str, str]:
    """
    Gemini APIã‚’ä½¿ç”¨ã—ã¦æ—¥è¨˜ã‚’ç”Ÿæˆ
    """
    api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("SEED_GUIDE_GEMINI_KEY")
    if not api_key:
        raise RuntimeError("Gemini API key not configured")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = build_diary_prompt(date, statistics, events, vegetable_info)
    
    # Gemini APIå‘¼ã³å‡ºã—
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={api_key}"
    
    payload = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }],
        "generationConfig": {
            "temperature": 0.7,
            "topP": 0.9,
            "maxOutputTokens": 1000
        }
    }
    
    headers = {"Content-Type": "application/json"}
    
    response = requests.post(url, headers=headers, json=payload, timeout=60)
    
    if response.status_code != 200:
        raise RuntimeError(f"Gemini API error: {response.status_code} - {response.text}")
    
    result = response.json()
    generated_text = result["candidates"][0]["content"]["parts"][0]["text"]
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
    return parse_diary_response(generated_text)

def build_diary_prompt(
    date: str,
    statistics: Dict,
    events: List[Dict],
    vegetable_info: Dict
) -> str:
    """æ—¥è¨˜ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
    
    veg_name = vegetable_info.get("name", "é‡èœ") if vegetable_info else "é‡èœ"
    
    # ã‚¤ãƒ™ãƒ³ãƒˆè¦ç´„
    event_summary = "\n".join([
        f"- {e['time']}: {e.get('device', '')} {e['action']}"
        for e in events[:10]
    ])
    
    prompt = f"""ã‚ãªãŸã¯æ¤ç‰©æ ½åŸ¹ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã¨ã«ã€è‚²æˆæ—¥è¨˜ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€æ—¥ä»˜ã€‘
{date}

ã€è‚²æˆä¸­ã®æ¤ç‰©ã€‘
{veg_name}

ã€ç’°å¢ƒãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã€‘
æ¸©åº¦: æœ€ä½ {statistics['temperature']['min']}Â°C / æœ€é«˜ {statistics['temperature']['max']}Â°C / å¹³å‡ {statistics['temperature']['avg']}Â°C
æ¹¿åº¦: æœ€ä½ {statistics['humidity']['min']}% / æœ€é«˜ {statistics['humidity']['max']}% / å¹³å‡ {statistics['humidity']['avg']}%
åœŸå£Œæ°´åˆ†: æœ€ä½ {statistics['soil_moisture']['min']}% / æœ€é«˜ {statistics['soil_moisture']['max']}% / å¹³å‡ {statistics['soil_moisture']['avg']}%

ã€ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆã€‘
{event_summary if event_summary else "ç‰¹ã«ãªã—"}

ä»¥ä¸‹ã®3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ã¦æ—¥è¨˜ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. **ä»Šæ—¥ã®è¦ç´„** (200-300æ–‡å­—)
   - 1æ—¥ã®ç’°å¢ƒçŠ¶æ…‹ã¨å…¨ä½“çš„ãªæ§˜å­ã‚’è¦ç´„
   - ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ç‰¹å¾´çš„ãªç‚¹ã‚’è¨˜è¼‰

2. **æˆé•·è¦³å¯Ÿ** (100-200æ–‡å­—)
   - æ¤ç‰©ã®çŠ¶æ…‹ã«ã¤ã„ã¦æ¨æ¸¬ã•ã‚Œã‚‹è¦³å¯Ÿ
   - ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ¤æ–­ã§ãã‚‹æˆé•·ã®é€²æ—

3. **æ˜æ—¥ã¸ã®ææ¡ˆ** (100-150æ–‡å­—)
   - ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ”¹å–„ææ¡ˆ
   - æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚„æ³¨æ„ç‚¹

å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼‰ï¼š
```json
{{
  "summary": "ä»Šæ—¥ã®è¦ç´„æ–‡...",
  "observations": "æˆé•·è¦³å¯Ÿæ–‡...",
  "recommendations": "æ˜æ—¥ã¸ã®ææ¡ˆæ–‡..."
}}
```

æ—¥è¨˜ã¯è¦ªã—ã¿ã‚„ã™ãã€å°‚é–€çš„ã™ããªã„æ–‡ä½“ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""
    
    return prompt

def parse_diary_response(text: str) -> Dict[str, str]:
    """AIå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹"""
    try:
        # JSONã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        clean_text = text.strip()
        if "```json" in clean_text:
            clean_text = clean_text.split("```json")[1].split("```")[0]
        elif "```" in clean_text:
            clean_text = clean_text.split("```")[1].split("```")[0]
        
        parsed = json.loads(clean_text.strip())
        
        return {
            "summary": parsed.get("summary", ""),
            "observations": parsed.get("observations", ""),
            "recommendations": parsed.get("recommendations", "")
        }
    except Exception as e:
        logging.error(f"Failed to parse AI response: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¦ç´„ã¨ã—ã¦ä½¿ç”¨
        return {
            "summary": text[:300],
            "observations": "ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­ã§ã™ã€‚",
            "recommendations": "å¼•ãç¶šãè¦³å¯Ÿã‚’ç¶šã‘ã¾ã™ã€‚"
        }
```

### 7. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼

```python
# backend/diary_service.py
async def process_daily_diary(target_date_str: str):
    """
    æ—¥è¨˜ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    import time
    start_time = time.time()
    
    try:
        target_date = date.fromisoformat(target_date_str)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆæœŸåŒ–
        diary_id = target_date_str
        await init_diary_status(diary_id)
        
        # 1. ãƒ‡ãƒ¼ã‚¿åé›†
        logging.info(f"Collecting data for {target_date_str}...")
        daily_data = await collect_daily_data(target_date)
        
        # 2. çµ±è¨ˆè¨ˆç®—
        statistics = calculate_statistics(daily_data["sensor_data"])
        events = extract_key_events(daily_data["agent_logs"])
        
        # 3. AIç”Ÿæˆ
        logging.info(f"Generating diary with AI for {target_date_str}...")
        ai_content = await generate_diary_with_ai(
            target_date_str,
            statistics,
            events,
            daily_data["vegetable"]
        )
        
        # 4. ä¿å­˜
        generation_time_ms = int((time.time() - start_time) * 1000)
        
        diary_data = {
            "date": target_date_str,
            "created_at": datetime.now(),
            "vegetable_id": daily_data["vegetable"].get("id") if daily_data["vegetable"] else None,
            "vegetable_name": daily_data["vegetable"].get("name") if daily_data["vegetable"] else None,
            "statistics": statistics,
            "events": events,
            "ai_summary": ai_content["summary"],
            "observations": ai_content["observations"],
            "recommendations": ai_content["recommendations"],
            "plant_image_url": daily_data["plant_image"],
            "generation_status": "completed",
            "generation_time_ms": generation_time_ms
        }
        
        await save_diary(diary_id, diary_data)
        
        logging.info(f"Diary generated successfully for {target_date_str} in {generation_time_ms}ms")
        
    except Exception as e:
        logging.error(f"Failed to generate diary for {target_date_str}: {e}")
        await mark_diary_failed(diary_id, str(e))

async def init_diary_status(diary_id: str):
    """æ—¥è¨˜ç”Ÿæˆé–‹å§‹"""
    if db is None:
        return
    
    db.collection("growing_diaries").document(diary_id).set({
        "generation_status": "processing",
        "created_at": datetime.now()
    })

async def save_diary(diary_id: str, data: Dict):
    """æ—¥è¨˜ã‚’ä¿å­˜"""
    if db is None:
        logging.warning("DB not available, cannot save diary")
        return
    
    db.collection("growing_diaries").document(diary_id).set(data)
    logging.info(f"Diary saved: {diary_id}")

async def mark_diary_failed(diary_id: str, error: str):
    """å¤±æ•—ãƒãƒ¼ã‚¯"""
    if db is None:
        return
    
    db.collection("growing_diaries").document(diary_id).update({
        "generation_status": "failed",
        "error_message": error,
        "updated_at": datetime.now()
    })
```

## ğŸ¨ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨­è¨ˆ

### 1. ãƒšãƒ¼ã‚¸æ§‹æˆ

æ–°ã—ã„ãƒšãƒ¼ã‚¸: `/diary` ã¾ãŸã¯ `/growing-diary`

```tsx
// frontend/app/diary/page.tsx
'use client'

import { useState, useEffect } from 'react'
import { Calendar, Sprout, TrendingUp, AlertCircle } from 'lucide-react'

interface GrowingDiary {
  date: string
  vegetable_name?: string
  statistics: {
    temperature: { min: number; max: number; avg: number }
    humidity: { min: number; max: number; avg: number }
    soil_moisture: { min: number; max: number; avg: number }
  }
  ai_summary: string
  observations: string
  recommendations: string
  plant_image_url?: string
}

export default function DiaryPage() {
  const [diaries, setDiaries] = useState<GrowingDiary[]>([])
  const [selectedDate, setSelectedDate] = useState<string | null>(null)
  
  useEffect(() => {
    // Fetch recent diaries
    fetch('/api/diary/list?limit=30')
      .then(res => res.json())
      .then(data => setDiaries(data.diaries || []))
  }, [])
  
  const selectedDiary = diaries.find(d => d.date === selectedDate)
  
  return (
    <div className="container mx-auto p-6">
      <h1 className="text-3xl font-bold mb-6">
        <Sprout className="inline mr-2" />
        è‚²æˆæ—¥è¨˜
      </h1>
      
      {/* Calendar/List View */}
      <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
        {/* Diary List */}
        <div className="lg:col-span-1">
          <DiaryList 
            diaries={diaries} 
            onSelect={setSelectedDate}
            selected={selectedDate}
          />
        </div>
        
        {/* Diary Detail */}
        <div className="lg:col-span-2">
          {selectedDiary ? (
            <DiaryDetail diary={selectedDiary} />
          ) : (
            <EmptyState />
          )}
        </div>
      </div>
    </div>
  )
}
```

### 2. APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

```python
# backend/main.py

@app.get("/api/diary/list")
async def list_diaries(limit: int = 30, offset: int = 0):
    """è‚²æˆæ—¥è¨˜ä¸€è¦§å–å¾—"""
    if db is None:
        return {"diaries": []}
    
    try:
        docs = db.collection("growing_diaries") \
            .where("generation_status", "==", "completed") \
            .order_by("date", direction=firestore.Query.DESCENDING) \
            .limit(limit) \
            .offset(offset) \
            .stream()
        
        diaries = []
        for doc in docs:
            diary = doc.to_dict()
            diary['id'] = doc.id
            diaries.append(diary)
        
        return {"diaries": diaries}
    except Exception as e:
        logging.error(f"Error fetching diaries: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/diary/{date}")
async def get_diary(date: str):
    """ç‰¹å®šæ—¥ã®æ—¥è¨˜å–å¾—"""
    if db is None:
        raise HTTPException(status_code=503, detail="Database unavailable")
    
    try:
        doc = db.collection("growing_diaries").document(date).get()
        
        if not doc.exists:
            raise HTTPException(status_code=404, detail="Diary not found")
        
        diary = doc.to_dict()
        diary['id'] = doc.id
        return diary
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error fetching diary: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/diary/generate-daily")
async def generate_daily_diary(background_tasks: BackgroundTasks):
    """
    æ—¥æ¬¡æ—¥è¨˜ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆCloud Schedulerã‹ã‚‰å‘¼ã³å‡ºã—ï¼‰
    """
    # å‰æ—¥ã®æ—¥è¨˜ã‚’ç”Ÿæˆï¼ˆ23:50å®Ÿè¡Œã‚’æƒ³å®šï¼‰
    target_date = (datetime.now() - timedelta(hours=1)).date()
    
    background_tasks.add_task(
        process_daily_diary,
        target_date.isoformat()
    )
    
    return {
        "status": "accepted",
        "date": target_date.isoformat(),
        "message": "Diary generation started"
    }

@app.post("/api/diary/generate-manual")
async def generate_manual_diary(
    background_tasks: BackgroundTasks,
    date: str
):
    """
    æ‰‹å‹•æ—¥è¨˜ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆãƒ»å†ç”Ÿæˆç”¨ï¼‰
    """
    try:
        # æ—¥ä»˜ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        target_date = date_module.fromisoformat(date)
        
        background_tasks.add_task(
            process_daily_diary,
            date
        )
        
        return {
            "status": "accepted",
            "date": date,
            "message": "Manual diary generation started"
        }
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid date format")
```

## ğŸš€ å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: åŸºæœ¬æ©Ÿèƒ½å®Ÿè£…ï¼ˆ1é€±é–“ï¼‰

- [ ] **Day 1-2**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åŸºç¤
  - [ ] `diary_service.py` ä½œæˆ
  - [ ] ãƒ‡ãƒ¼ã‚¿åé›†é–¢æ•°å®Ÿè£…
  - [ ] çµ±è¨ˆè¨ˆç®—é–¢æ•°å®Ÿè£…
  - [ ] Firestore ã‚¹ã‚­ãƒ¼ãƒä½œæˆ

- [ ] **Day 3-4**: AIçµ±åˆ
  - [ ] Gemini APIé€£æºå®Ÿè£…
  - [ ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
  - [ ] ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹å‡¦ç†
  - [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

- [ ] **Day 5-6**: API & ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
  - [ ] APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
  - [ ] Cloud Schedulerè¨­å®š
  - [ ] èªè¨¼ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
  - [ ] ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

- [ ] **Day 7**: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰åŸºç¤
  - [ ] æ—¥è¨˜ä¸€è¦§ãƒšãƒ¼ã‚¸ä½œæˆ
  - [ ] æ—¥è¨˜è©³ç´°è¡¨ç¤º
  - [ ] åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°

### Phase 2: UIå¼·åŒ–ï¼ˆ3-4æ—¥ï¼‰

- [ ] **Day 8-9**: UI/UXæ”¹å–„
  - [ ] ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ“ãƒ¥ãƒ¼è¿½åŠ 
  - [ ] ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½
  - [ ] ã‚½ãƒ¼ãƒˆæ©Ÿèƒ½
  - [ ] ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³

- [ ] **Day 10-11**: è¿½åŠ æ©Ÿèƒ½
  - [ ] æ¤ç‰©ç”»åƒè¡¨ç¤º
  - [ ] ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼‰
  - [ ] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ï¼ˆPDF/CSVï¼‰
  - [ ] æ¤œç´¢æ©Ÿèƒ½

### Phase 3: æœ€é©åŒ–ãƒ»ç›£è¦–ï¼ˆ2-3æ—¥ï¼‰

- [ ] **Day 12-13**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
  - [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°å®Ÿè£…
  - [ ] ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
  - [ ] ç”»åƒæœ€é©åŒ–
  - [ ] ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€Ÿåº¦æ”¹å–„

- [ ] **Day 14**: ç›£è¦–ãƒ»é‹ç”¨
  - [ ] ãƒ­ã‚°è¨­å®š
  - [ ] ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
  - [ ] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ
  - [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹æˆæœç‰©

1. **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**
   - `backend/diary_service.py` - æ—¥è¨˜ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹
   - `backend/main.py` - æ–°è¦APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¿½åŠ 
   - `backend/tests/test_diary_service.py` - ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

2. **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**
   - `frontend/app/diary/page.tsx` - æ—¥è¨˜ä¸€è¦§ãƒšãƒ¼ã‚¸
   - `frontend/components/diary-card.tsx` - æ—¥è¨˜ã‚«ãƒ¼ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
   - `frontend/components/diary-detail.tsx` - è©³ç´°è¡¨ç¤ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

3. **ã‚¤ãƒ³ãƒ•ãƒ©**
   - Cloud Schedulerè¨­å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ
   - ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †æ›¸
   - é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«

4. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**
   - APIä»•æ§˜æ›¸
   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒå®šç¾©
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

1. **Cloud Schedulerèªè¨¼**
   ```python
   from google.oauth2 import id_token
   from google.auth.transport import requests
   
   def verify_scheduler_request(request: Request):
       """Cloud Schedulerã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ¤œè¨¼"""
       try:
           # OIDC ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼
           token = request.headers.get('Authorization', '').replace('Bearer ', '')
           claim = id_token.verify_oauth2_token(token, requests.Request())
           
           # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç¢ºèª
           expected_email = "scheduler@PROJECT_ID.iam.gserviceaccount.com"
           if claim.get('email') != expected_email:
               raise HTTPException(status_code=403, detail="Unauthorized")
      MCP -->|Notification| Discord
    
    %% Styling
    classDef default fill:#f9f9f9,stroke:#333,stroke-width:1px;ail="Invalid token")
   ```

2. **ãƒ¬ãƒ¼ãƒˆåˆ¶é™**
   - æ‰‹å‹•ç”ŸæˆAPIã«åˆ¶é™ã‚’è¨­å®šï¼ˆ1ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Š1æ—¥10å›ã¾ã§ï¼‰

3. **ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼**
   - æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å³å¯†ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
   - SQL/NoSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–

## ğŸ’° ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

### æœˆé–“ã‚³ã‚¹ãƒˆæ¦‚ç®—ï¼ˆ1æ—¥1å›å®Ÿè¡Œï¼‰

1. **Cloud Scheduler**: $0.10/æœˆï¼ˆ1ã‚¸ãƒ§ãƒ–ï¼‰
2. **Gemini API**: ç´„$1-2/æœˆ
   - 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆç´„1,000ãƒˆãƒ¼ã‚¯ãƒ³ Ã— 30æ—¥ = 30,000ãƒˆãƒ¼ã‚¯ãƒ³
   - Gemini Flash: $0.00002/1Kãƒˆãƒ¼ã‚¯ãƒ³
3. **Firestore**:
   - æ›¸ãè¾¼ã¿: 30å›/æœˆ = ã»ã¼ç„¡æ–™
   - èª­ã¿å–ã‚Š: 300å›/æœˆï¼ˆæ¨å®šï¼‰ = ã»ã¼ç„¡æ–™
4. **Cloud Run**: å¢—åˆ†ã‚³ã‚¹ãƒˆã»ã¼ãªã—ï¼ˆæ—¢å­˜å®Ÿè¡Œæ™‚é–“å†…ï¼‰

**åˆè¨ˆ**: ç´„$1-3/æœˆï¼ˆéå¸¸ã«ä½ã‚³ã‚¹ãƒˆï¼‰

## ğŸ¯ æˆåŠŸæŒ‡æ¨™ï¼ˆKPIï¼‰

1. **ç”ŸæˆæˆåŠŸç‡**: > 95%
2. **ç”Ÿæˆæ™‚é–“**: < 30ç§’/æ—¥è¨˜
3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼é–²è¦§ç‡**: > 50%ï¼ˆç”Ÿæˆæ—¥è¨˜ã®ã†ã¡é–²è¦§ã•ã‚Œã‚‹ã‚‚ã®ï¼‰
4. **AIå“è³ªã‚¹ã‚³ã‚¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ 4/5ä»¥ä¸Š

## ğŸ“ ä»Šå¾Œã®æ‹¡å¼µã‚¢ã‚¤ãƒ‡ã‚¢

1. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ©Ÿèƒ½**
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¥è¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè©³ç´°/ç°¡æ½”ï¼‰
   - è¿½è¨˜æ©Ÿèƒ½ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ãƒ¡ãƒ¢è¿½åŠ ï¼‰

2. **åˆ†ææ©Ÿèƒ½**
   - é€±æ¬¡ãƒ»æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
   - æˆé•·æ›²ç·šã®å¯è¦–åŒ–
   - ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ©ãƒ¼ãƒˆ

3. **å…±æœ‰æ©Ÿèƒ½**
   - SNSã‚·ã‚§ã‚¢
   - PDFå‡ºåŠ›
   - æ ½åŸ¹è¨˜éŒ²ã®å…¬é–‹ãƒ»å…±æœ‰

4. **å¤šè¨€èªå¯¾å¿œ**
   - è‹±èªæ—¥è¨˜ç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
   - ç¿»è¨³æ©Ÿèƒ½

5. **éŸ³å£°èª­ã¿ä¸Šã’**
   - æ—¥è¨˜ã®éŸ³å£°åŒ–
   - ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

---

**ä½œæˆæ—¥**: 2025-02-04  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: è¨­è¨ˆå®Œäº†ã€å®Ÿè£…æº–å‚™å®Œäº†
